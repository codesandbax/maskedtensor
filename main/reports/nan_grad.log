Traceback (most recent call last):
  File "/home/runner/.local/lib/python3.8/site-packages/jupyter_cache/executors/utils.py", line 51, in single_nb_execution
    executenb(
  File "/home/runner/.local/lib/python3.8/site-packages/nbclient/client.py", line 1204, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
  File "/home/runner/.local/lib/python3.8/site-packages/nbclient/util.py", line 84, in wrapped
    return just_run(coro(*args, **kwargs))
  File "/home/runner/.local/lib/python3.8/site-packages/nbclient/util.py", line 62, in just_run
    return loop.run_until_complete(coro)
  File "/usr/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/home/runner/.local/lib/python3.8/site-packages/nbclient/client.py", line 663, in async_execute
    await self.async_execute_cell(
  File "/home/runner/.local/lib/python3.8/site-packages/nbclient/client.py", line 965, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/home/runner/.local/lib/python3.8/site-packages/nbclient/client.py", line 862, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
x = torch.tensor([-10., -5, 0, 5, 10, 50, 60, 70, 80, 90, 100], requires_grad=True)
mask = x < 0
mx = masked_tensor(x, mask, requires_grad=True)
my = masked_tensor(torch.ones_like(x), ~mask, requires_grad=True)
y = torch.where(mask, torch.exp(mx), my)
s = y.sum()
s.backward()
# Gradient is only provided to selected subset.
# Effectively this changes the gradient of where to mask out elements instead
# of setting them to zero.
print("mx.grad: ", mx.grad)
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mRuntimeError[0m                              Traceback (most recent call last)
Input [0;32mIn [3][0m, in [0;36m<cell line: 5>[0;34m()[0m
[1;32m      3[0m mx [38;5;241m=[39m masked_tensor(x, mask, requires_grad[38;5;241m=[39m[38;5;28;01mTrue[39;00m)
[1;32m      4[0m my [38;5;241m=[39m masked_tensor(torch[38;5;241m.[39mones_like(x), [38;5;241m~[39mmask, requires_grad[38;5;241m=[39m[38;5;28;01mTrue[39;00m)
[0;32m----> 5[0m y [38;5;241m=[39m [43mtorch[49m[38;5;241;43m.[39;49m[43mwhere[49m[43m([49m[43mmask[49m[43m,[49m[43m [49m[43mtorch[49m[38;5;241;43m.[39;49m[43mexp[49m[43m([49m[43mmx[49m[43m)[49m[43m,[49m[43m [49m[43mmy[49m[43m)[49m
[1;32m      6[0m s [38;5;241m=[39m y[38;5;241m.[39msum()
[1;32m      7[0m s[38;5;241m.[39mbackward()

File [0;32m~/.local/lib/python3.8/site-packages/maskedtensor/core.py:210[0m, in [0;36mMaskedTensor.__torch_function__[0;34m(cls, func, types, args, kwargs)[0m
[1;32m    208[0m     [38;5;28;01massert[39;00m [38;5;28mlen[39m(args) [38;5;241m==[39m [38;5;241m3[39m
[1;32m    209[0m     [38;5;28;01massert[39;00m [38;5;28mlen[39m(kwargs) [38;5;241m==[39m [38;5;241m0[39m
[0;32m--> 210[0m     [38;5;28;01mreturn[39;00m [43mMaskedWhere[49m[38;5;241;43m.[39;49m[43mapply[49m[43m([49m[38;5;241;43m*[39;49m[43margs[49m[43m)[49m
[1;32m    211[0m [38;5;28;01mif[39;00m func [38;5;129;01mis[39;00m torch[38;5;241m.[39mTensor[38;5;241m.[39mcontiguous:
[1;32m    212[0m     [38;5;28;01mreturn[39;00m MaskedContigous[38;5;241m.[39mapply(args[[38;5;241m0[39m])

File [0;32m~/.local/lib/python3.8/site-packages/maskedtensor/core.py:97[0m, in [0;36mMaskedWhere.forward[0;34m(ctx, cond, self, other)[0m
[1;32m     95[0m ctx[38;5;241m.[39mmark_non_differentiable(cond)
[1;32m     96[0m ctx[38;5;241m.[39msave_for_backward(cond)
[0;32m---> 97[0m [38;5;28;01mreturn[39;00m [43mtorch[49m[38;5;241;43m.[39;49m[43mops[49m[38;5;241;43m.[39;49m[43maten[49m[38;5;241;43m.[39;49m[43mwhere[49m[43m([49m[43mcond[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[43m,[49m[43m [49m[43mother[49m[43m)[49m

File [0;32m~/.local/lib/python3.8/site-packages/torch/_ops.py:142[0m, in [0;36mOpOverloadPacket.__call__[0;34m(self, *args, **kwargs)[0m
[1;32m    137[0m [38;5;28;01mdef[39;00m [38;5;21m__call__[39m([38;5;28mself[39m, [38;5;241m*[39margs, [38;5;241m*[39m[38;5;241m*[39mkwargs):
[1;32m    138[0m     [38;5;66;03m# overloading __call__ to ensure torch.ops.foo.bar()[39;00m
[1;32m    139[0m     [38;5;66;03m# is still callable from JIT[39;00m
[1;32m    140[0m     [38;5;66;03m# We save the function ptr as the `op` attribute on[39;00m
[1;32m    141[0m     [38;5;66;03m# OpOverloadPacket to access it here.[39;00m
[0;32m--> 142[0m     [38;5;28;01mreturn[39;00m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43m_op[49m[43m([49m[38;5;241;43m*[39;49m[43margs[49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m [49m[38;5;129;43;01mor[39;49;00m[43m [49m[43m{[49m[43m}[49m[43m)[49m

File [0;32m~/.local/lib/python3.8/site-packages/maskedtensor/core.py:217[0m, in [0;36mMaskedTensor.__torch_function__[0;34m(cls, func, types, args, kwargs)[0m
[1;32m    215[0m logging[38;5;241m.[39mdebug([38;5;124m"[39m[38;5;124mtf redispatching to td[39m[38;5;124m"[39m)
[1;32m    216[0m [38;5;28;01mwith[39;00m torch[38;5;241m.[39m_C[38;5;241m.[39mDisableTorchFunction():
[0;32m--> 217[0m     ret [38;5;241m=[39m [43mfunc[49m[43m([49m[38;5;241;43m*[39;49m[43margs[49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m
[1;32m    218[0m     [38;5;28;01mif[39;00m func [38;5;129;01min[39;00m get_default_nowrap_functions():
[1;32m    219[0m         [38;5;28;01mreturn[39;00m ret

File [0;32m~/.local/lib/python3.8/site-packages/torch/_ops.py:142[0m, in [0;36mOpOverloadPacket.__call__[0;34m(self, *args, **kwargs)[0m
[1;32m    137[0m [38;5;28;01mdef[39;00m [38;5;21m__call__[39m([38;5;28mself[39m, [38;5;241m*[39margs, [38;5;241m*[39m[38;5;241m*[39mkwargs):
[1;32m    138[0m     [38;5;66;03m# overloading __call__ to ensure torch.ops.foo.bar()[39;00m
[1;32m    139[0m     [38;5;66;03m# is still callable from JIT[39;00m
[1;32m    140[0m     [38;5;66;03m# We save the function ptr as the `op` attribute on[39;00m
[1;32m    141[0m     [38;5;66;03m# OpOverloadPacket to access it here.[39;00m
[0;32m--> 142[0m     [38;5;28;01mreturn[39;00m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43m_op[49m[43m([49m[38;5;241;43m*[39;49m[43margs[49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m [49m[38;5;129;43;01mor[39;49;00m[43m [49m[43m{[49m[43m}[49m[43m)[49m

File [0;32m~/.local/lib/python3.8/site-packages/maskedtensor/core.py:320[0m, in [0;36mMaskedTensor.__torch_dispatch__[0;34m(cls, func, types, args, kwargs)[0m
[1;32m    318[0m     func(data, get_data(args[[38;5;241m1[39m]))
[1;32m    319[0m     [38;5;28;01mreturn[39;00m args[[38;5;241m0[39m]
[0;32m--> 320[0m [38;5;28;01mif[39;00m func [38;5;129;01min[39;00m [[43mtorch[49m[38;5;241;43m.[39;49m[43mops[49m[38;5;241;43m.[39;49m[43maten[49m[38;5;241;43m.[39;49m[43m_s_where[49m]:
[1;32m    321[0m     [38;5;28;01massert[39;00m [38;5;28mlen[39m(kwargs) [38;5;241m==[39m [38;5;241m0[39m
[1;32m    322[0m     [38;5;28;01massert[39;00m [38;5;28mlen[39m(args) [38;5;241m==[39m [38;5;241m3[39m

File [0;32m~/.local/lib/python3.8/site-packages/torch/_ops.py:191[0m, in [0;36m_OpNamespace.__getattr__[0;34m(self, op_name)[0m
[1;32m    189[0m namespace_name [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mname
[1;32m    190[0m qualified_op_name [38;5;241m=[39m [38;5;124m'[39m[38;5;132;01m{}[39;00m[38;5;124m::[39m[38;5;132;01m{}[39;00m[38;5;124m'[39m[38;5;241m.[39mformat(namespace_name, op_name)
[0;32m--> 191[0m op [38;5;241m=[39m [43mtorch[49m[38;5;241;43m.[39;49m[43m_C[49m[38;5;241;43m.[39;49m[43m_jit_get_operation[49m[43m([49m[43mqualified_op_name[49m[43m)[49m
[1;32m    193[0m [38;5;66;03m# let the script frontend know that op is identical to the builtin op[39;00m
[1;32m    194[0m [38;5;66;03m# with qualified_op_name[39;00m
[1;32m    195[0m torch[38;5;241m.[39mjit[38;5;241m.[39m_builtins[38;5;241m.[39m_register_builtin(op, qualified_op_name)

[0;31mRuntimeError[0m: No such operator aten::_s_where
RuntimeError: No such operator aten::_s_where

