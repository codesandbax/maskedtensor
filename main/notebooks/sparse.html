<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Sparse semantics &mdash; MaskedTensor main documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/mystnb.css" type="text/css" />
      <link rel="stylesheet" href="../_static/togglebutton.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script>let toggleHintShow = 'Click to show';</script>
        <script>let toggleHintHide = 'Click to hide';</script>
        <script>let toggleOpenOnPrint = 'true';</script>
        <script src="../_static/togglebutton.js"></script>
        <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Distinguishing between 0 and NaN gradient" href="nan_grad.html" />
    <link rel="prev" title="Overview of MaskedTensors" href="overview.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
  <a href="../index.html" class="icon icon-home"> MaskedTensor
  </a>
    <div class="version">
      <a href='https://pytorch.org/maskedtensor/versions.html' style="color:#FFFFFF">main (0.12.0+git8b3c5a5) &#x25BC</a>
    </div>
    
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../install.html">Installation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="overview.html">Overview of MaskedTensors</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Sparse semantics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="#principles">Principles</a></li>
<li class="toctree-l2"><a class="reference internal" href="#sparse-coo-tensors">Sparse COO Tensors</a></li>
<li class="toctree-l2"><a class="reference internal" href="#sparse-csr-tensors">Sparse CSR Tensors</a></li>
<li class="toctree-l2"><a class="reference internal" href="#supported-operations">Supported Operations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#unary">Unary</a></li>
<li class="toctree-l3"><a class="reference internal" href="#binary">Binary</a></li>
<li class="toctree-l3"><a class="reference internal" href="#reductions">Reductions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#maskedtensor-methods-and-sparse">MaskedTensor methods and sparse</a></li>
<li class="toctree-l2"><a class="reference internal" href="#appendix">Appendix</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#sparse-coo-construction">Sparse COO construction</a></li>
<li class="toctree-l3"><a class="reference internal" href="#sparse-csr">Sparse CSR</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="nan_grad.html">Distinguishing between 0 and NaN gradient</a></li>
<li class="toctree-l1"><a class="reference internal" href="safe_softmax.html">Safe Softmax</a></li>
<li class="toctree-l1"><a class="reference internal" href="issue_1369.html">Efficiency of writing “sparse” semantics for Adagrad</a></li>
<li class="toctree-l1"><a class="reference internal" href="nan_operators.html">Implemented missing torch.nan* operators</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../unary.html">Unary Operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../binary.html">Binary Operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reductions.html">Reductions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../view_and_select.html">View and select functions</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MaskedTensor</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Sparse semantics</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/pytorch/maskedtensor/blob/main/docs/source/notebooks/sparse.ipynb" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="sparse-semantics">
<h1>Sparse semantics<a class="headerlink" href="#sparse-semantics" title="Permalink to this heading"></a></h1>
<p><a class="reference external" href="https://colab.research.google.com/github/pytorch/maskedtensor/blob/main/docs/source/notebooks/sparse.ipynb"><img alt="Open in Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this heading"></a></h2>
<p><a class="reference external" href="https://pytorch.org/docs/stable/sparse.html">Sparsity in PyTorch</a> is a quickly growing area that has found a lot of support and demand due to its efficiency in both memory and compute. This tutorial is meant to be used in conjunction with the the PyTorch link above, as the sparse tensors are ultimately the building blocks for MaskedTensors (just as regular <code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code>s are as well).</p>
<p>Sparse storage formats have been proven to be powerful in a variety of ways. As a primer, the first use case most practitioners think about is when the majority of elements are equal to zero (a high degree of sparsity), but even in cases of lower sparsity, certain formats (e.g. BSR) can take advantage of substructures within a matrix. There are a number of different <a class="reference external" href="https://en.wikipedia.org/wiki/Sparse_matrix">sparse storage formats</a> that can be leveraged with various tradeoffs and degrees of adoption.</p>
<p>“Specified” and “unspecified” elements (e.g. elements that are stored vs. not) have a long history in PyTorch without formal semantics and certainly without consistency; indeed, MaskedTensor was partially born out of a build up of issues (e.g. the <a class="reference external" href="https://pytorch.org/maskedtensor/main/notebooks/nan_grad.html">nan_grad tutorial</a>) that vanilla tensors could not address. A major goal of the MaskedTensor project is to become the primary source of truth for specified/unspecified semantics where they are a first class citizen instead of an afterthought.</p>
<div class="alert alert-info">
<p>Note: Currently, only the COO and CSR sparse storage formats are supported in MaskedTensor (BSR and CSC will be developed in the future). If you have another format that you would like supported, please file an issue!</p>
</div></section>
<section id="principles">
<h2>Principles<a class="headerlink" href="#principles" title="Permalink to this heading"></a></h2>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">input</span></code> and <code class="docutils literal notranslate"><span class="pre">mask</span></code> must have the same storage format, whether that’s <code class="docutils literal notranslate"><span class="pre">torch.strided</span></code>, <code class="docutils literal notranslate"><span class="pre">torch.sparse_coo</span></code>, or <code class="docutils literal notranslate"><span class="pre">torch.sparse_csr</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">input</span></code> and <code class="docutils literal notranslate"><span class="pre">mask</span></code> must have the same size, indicated by <code class="docutils literal notranslate"><span class="pre">t.size()</span></code></p></li>
</ol>
</section>
<section id="sparse-coo-tensors">
<h2>Sparse COO Tensors<a class="headerlink" href="#sparse-coo-tensors" title="Permalink to this heading"></a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">maskedtensor</span> <span class="kn">import</span> <span class="n">masked_tensor</span>
</pre></div>
</div>
</div>
</div>
<p>In accordance with Principle #1, a sparse MaskedTensor is created by passing in two sparse tensors, which can be initialized with any of the constructors, e.g. <code class="docutils literal notranslate"><span class="pre">torch.sparse_coo_tensor</span></code>.</p>
<p>As a recap of <a class="reference external" href="https://pytorch.org/docs/stable/sparse.html#sparse-coo-tensors">sparse COO tensors</a>, the COO format stands for “Coordinate format”, where the specified elements are stored as tuples of their indices and the corresponding values. That is, the following are provided:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">indices</span></code>: array of size <code class="docutils literal notranslate"><span class="pre">(ndim,</span> <span class="pre">nse)</span></code> and dtype <code class="docutils literal notranslate"><span class="pre">torch.int64</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">values</span></code>: array of size <code class="docutils literal notranslate"><span class="pre">(nse,)</span></code> with any integer or floating point number dtype</p></li>
</ul>
<p>where <code class="docutils literal notranslate"><span class="pre">ndim</span></code> is the dimensionality of the tensor and <code class="docutils literal notranslate"><span class="pre">nse</span></code> is the number of specified elements</p>
<p>For both sparse COO and CSR tensors, you can construct them by doing either:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">masked_tensor(sparse_tensor_data,</span> <span class="pre">sparse_tensor_mask)</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dense_masked_tensor.to_sparse_coo()</span></code></p></li>
</ol>
<p>The is second is easier to illustrate so we have shown that below, but for more on the first and the nuances behind the approach, please read the Appendix at the bottom.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># To start, create a MaskedTensor</span>
<span class="n">values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
     <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
      <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">]]</span>
<span class="p">)</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
     <span class="p">[[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">],</span>
      <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">]]</span>
<span class="p">)</span>
<span class="n">mt</span> <span class="o">=</span> <span class="n">masked_tensor</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>

<span class="n">sparse_coo_mt</span> <span class="o">=</span> <span class="n">mt</span><span class="o">.</span><span class="n">to_sparse_coo</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;masked tensor:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">mt</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;sparse coo masked tensor:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">sparse_coo_mt</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;sparse data:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">sparse_coo_mt</span><span class="o">.</span><span class="n">data</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>masked tensor:
 masked_tensor(
  [
    [      --,       --, 3],
    [      --,       --, 5]
  ]
)
sparse coo masked tensor:
 masked_tensor(
  [
    [      --,       --, 3],
    [      --,       --, 5]
  ]
)
sparse data:
 tensor(indices=tensor([[0, 1],
                       [2, 2]]),
       values=tensor([3, 5]),
       size=(2, 3), nnz=2, layout=torch.sparse_coo)
</pre></div>
</div>
</div>
</div>
</section>
<section id="sparse-csr-tensors">
<h2>Sparse CSR Tensors<a class="headerlink" href="#sparse-csr-tensors" title="Permalink to this heading"></a></h2>
<p>Similarly, MaskedTensor also supports the <a class="reference external" href="https://pytorch.org/docs/stable/sparse.html#sparse-csr-tensor">CSR (Compressed Sparse Row)</a> sparse tensor format. Instead of storing the tuples of the indices like sparse COO tensors, sparse CSR tensors aim to decrease the memory requirements by storing compressed row indices. In particular, a CSR sparse tensor consists of three 1-D tensors:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">crow_indices</span></code>: array of compressed row indices with size <code class="docutils literal notranslate"><span class="pre">(size[0]</span> <span class="pre">+</span> <span class="pre">1,)</span></code>. This array indicates which row a given entry in <code class="docutils literal notranslate"><span class="pre">values</span></code> lives in. The last element is the number of specified elements, while <code class="docutils literal notranslate"><span class="pre">crow_indices[i+1]</span> <span class="pre">-</span> <span class="pre">crow_indices[i]</span></code> indicates the number of specified elements in row <code class="docutils literal notranslate"><span class="pre">i</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">col_indices</span></code>: array of size <code class="docutils literal notranslate"><span class="pre">(nnz,)</span></code>. Indicates the column indices for each value.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">values</span></code>: array of size <code class="docutils literal notranslate"><span class="pre">(nnz,)</span></code>. Contains the values of the CSR tensor.</p></li>
</ul>
<p>Of note, both sparse COO and CSR tensors are in a <a class="reference external" href="https://pytorch.org/docs/stable/index.html">beta</a> state.</p>
<p>By way of example (and again, you can find more examples in the Appendix):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mt_sparse_csr</span> <span class="o">=</span> <span class="n">mt</span><span class="o">.</span><span class="n">to_sparse_csr</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;values:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">mt_sparse_csr</span><span class="o">.</span><span class="n">data</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;mask:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">mt_sparse_csr</span><span class="o">.</span><span class="n">mask</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;mt:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">mt_sparse_csr</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>values:
 tensor(crow_indices=tensor([0, 1, 2]),
       col_indices=tensor([2, 2]),
       values=tensor([3, 5]), size=(2, 3), nnz=2, layout=torch.sparse_csr)
mask:
 tensor(crow_indices=tensor([0, 1, 2]),
       col_indices=tensor([2, 2]),
       values=tensor([True, True]), size=(2, 3), nnz=2,
       layout=torch.sparse_csr)
mt:
 masked_tensor(
  [
    [      --,       --, 3],
    [      --,       --, 5]
  ]
)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/runner/.local/lib/python3.8/site-packages/maskedtensor/core.py:179: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:66.)
  sparse_mask = mask.to_sparse_csr()
</pre></div>
</div>
</div>
</div>
</section>
<section id="supported-operations">
<h2>Supported Operations<a class="headerlink" href="#supported-operations" title="Permalink to this heading"></a></h2>
<section id="unary">
<h3>Unary<a class="headerlink" href="#unary" title="Permalink to this heading"></a></h3>
<p><a class="reference external" href="https://pytorch.org/maskedtensor/main/unary.html">All unary operations are supported</a>, e.g.:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mt</span><span class="o">.</span><span class="n">sin</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>masked_tensor(
  [
    [      --,       --,   0.1411],
    [      --,       --,  -0.9589]
  ]
)
</pre></div>
</div>
</div>
</div>
</section>
<section id="binary">
<h3>Binary<a class="headerlink" href="#binary" title="Permalink to this heading"></a></h3>
<p><a class="reference external" href="https://pytorch.org/maskedtensor/main/binary.html">Binary operations are also supported</a>, but the input masks from the two masked tensors must match.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">i</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]</span>
<span class="n">v1</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="n">v2</span> <span class="o">=</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">40</span><span class="p">]</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">])</span>

<span class="n">s1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sparse_coo_tensor</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">v1</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">s2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sparse_coo_tensor</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">v2</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sparse_coo_tensor</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<span class="n">mt1</span> <span class="o">=</span> <span class="n">masked_tensor</span><span class="p">(</span><span class="n">s1</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
<span class="n">mt2</span> <span class="o">=</span> <span class="n">masked_tensor</span><span class="p">(</span><span class="n">s2</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;mt1:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">mt1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;mt2:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">mt2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;torch.div(mt2, mt1):</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">mt2</span><span class="p">,</span> <span class="n">mt1</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;torch.mul(mt1, mt2):</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">mt1</span><span class="p">,</span> <span class="n">mt2</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>mt1:
 masked_tensor(
  [
    [      --,       --, 3],
    [      --,       --, 5]
  ]
)
mt2:
 masked_tensor(
  [
    [      --,       --, 20],
    [      --,       --, 40]
  ]
)
torch.div(mt2, mt1):
 masked_tensor(
  [
    [      --,       --,   6.6667],
    [      --,       --,   8.0000]
  ]
)
torch.mul(mt1, mt2):
 masked_tensor(
  [
    [      --,       --, 60],
    [      --,       --, 200]
  ]
)
</pre></div>
</div>
</div>
</div>
</section>
<section id="reductions">
<h3>Reductions<a class="headerlink" href="#reductions" title="Permalink to this heading"></a></h3>
<p>At the moment, when the underlying data is sparse, only <a class="reference external" href="https://pytorch.org/maskedtensor/main/reductions.html">reductions</a> across all dimensions are supported and not a particular dimension (e.g. <code class="docutils literal notranslate"><span class="pre">mt.sum()</span></code> is supported but not <code class="docutils literal notranslate"><span class="pre">mt.sum(dim=1)</span></code>). This is next in line to work on.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;mt:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">mt</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;mt.sum():</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">mt</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;mt.amin():</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">mt</span><span class="o">.</span><span class="n">amin</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>mt:
 masked_tensor(
  [
    [      --,       --, 3],
    [      --,       --, 5]
  ]
)
mt.sum():
 masked_tensor(8, True)
mt.amin():
 masked_tensor(3, True)
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="maskedtensor-methods-and-sparse">
<h2>MaskedTensor methods and sparse<a class="headerlink" href="#maskedtensor-methods-and-sparse" title="Permalink to this heading"></a></h2>
<p><code class="docutils literal notranslate"><span class="pre">to_dense()</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mt</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>masked_tensor(
  [
    [      --,       --, 3],
    [      --,       --, 5]
  ]
)
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">to_sparse_coo()</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">v</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]]</span>
<span class="n">m</span> <span class="o">=</span> <span class="p">[[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">],</span>
     <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">]]</span>
<span class="n">mt</span> <span class="o">=</span> <span class="n">masked_tensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">v</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">m</span><span class="p">))</span>

<span class="n">mt_sparse</span> <span class="o">=</span> <span class="n">mt</span><span class="o">.</span><span class="n">to_sparse_coo</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">to_sparse_csr()</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">v</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]]</span>
<span class="n">m</span> <span class="o">=</span> <span class="p">[[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">],</span>
     <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">]]</span>
<span class="n">mt</span> <span class="o">=</span> <span class="n">masked_tensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">v</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">m</span><span class="p">))</span>

<span class="n">mt_sparse_csr</span> <span class="o">=</span> <span class="n">mt</span><span class="o">.</span><span class="n">to_sparse_csr</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">is_sparse</span></code> / <code class="docutils literal notranslate"><span class="pre">is_sparse_coo</span></code> / <code class="docutils literal notranslate"><span class="pre">is_sparse_csr</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;mt.is_sparse: &quot;</span><span class="p">,</span> <span class="n">mt</span><span class="o">.</span><span class="n">is_sparse</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;mt_sparse.is_sparse: &quot;</span><span class="p">,</span> <span class="n">mt_sparse</span><span class="o">.</span><span class="n">is_sparse</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;mt.is_sparse_coo: &quot;</span><span class="p">,</span> <span class="n">mt</span><span class="o">.</span><span class="n">is_sparse_coo</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;mt_sparse.is_sparse_coo: &quot;</span><span class="p">,</span> <span class="n">mt_sparse</span><span class="o">.</span><span class="n">is_sparse_coo</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;mt.is_sparse_csr: &quot;</span><span class="p">,</span> <span class="n">mt</span><span class="o">.</span><span class="n">is_sparse_csr</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;mt_sparse_csr.is_sparse_csr: &quot;</span><span class="p">,</span> <span class="n">mt_sparse_csr</span><span class="o">.</span><span class="n">is_sparse_csr</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>mt.is_sparse:  False
mt_sparse.is_sparse:  True
mt.is_sparse_coo:  False
mt_sparse.is_sparse_coo:  True
mt.is_sparse_csr:  False
mt_sparse_csr.is_sparse_csr:  True
</pre></div>
</div>
</div>
</div>
</section>
<section id="appendix">
<h2>Appendix<a class="headerlink" href="#appendix" title="Permalink to this heading"></a></h2>
<section id="sparse-coo-construction">
<h3>Sparse COO construction<a class="headerlink" href="#sparse-coo-construction" title="Permalink to this heading"></a></h3>
<p>Recall in our original example, we created a MaskedTensor and then converted it to a sparse COO MaskedTensor with <code class="docutils literal notranslate"><span class="pre">mt.to_sparse_coo()</span></code></p>
<p>Alternatively, we can also construct a sparse COO MaskedTensor by passing in two sparse COO tensors!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">]])</span><span class="o">.</span><span class="n">to_sparse</span><span class="p">()</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">],</span> <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">]])</span><span class="o">.</span><span class="n">to_sparse</span><span class="p">()</span>

<span class="n">mt</span> <span class="o">=</span> <span class="n">masked_tensor</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>  

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;values:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">values</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;mask:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;mt:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">mt</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>values:
 tensor(indices=tensor([[0, 1, 1],
                       [2, 0, 2]]),
       values=tensor([3, 4, 5]),
       size=(2, 3), nnz=3, layout=torch.sparse_coo)
mask:
 tensor(indices=tensor([[0, 1],
                       [2, 2]]),
       values=tensor([True, True]),
       size=(2, 3), nnz=2, layout=torch.sparse_coo)
mt:
 masked_tensor(
  [
    [      --,       --, 3],
    [      --,       --, 5]
  ]
)
</pre></div>
</div>
</div>
</div>
<p>Instead of doing <code class="docutils literal notranslate"><span class="pre">dense_tensor.to_sparse()</span></code>, we can also create the sparse COO tensors directly, which brings us to a word of warning: when using a function like <code class="docutils literal notranslate"><span class="pre">.to_sparse_coo()</span></code>, if the user does not specify the indices like in the above example, then 0 values will be default “unspecified”</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">i</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]</span>
<span class="n">v</span> <span class="o">=</span>  <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">])</span>

<span class="n">values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sparse_coo_tensor</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sparse_coo_tensor</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">mt2</span> <span class="o">=</span> <span class="n">masked_tensor</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;values:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">values</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;mask:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;mt2:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">mt2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>values:
 tensor(indices=tensor([[0, 1, 1],
                       [2, 0, 2]]),
       values=tensor([3, 4, 5]),
       size=(2, 3), nnz=3, layout=torch.sparse_coo)
mask:
 tensor(indices=tensor([[0, 1, 1],
                       [2, 0, 2]]),
       values=tensor([ True, False,  True]),
       size=(2, 3), nnz=3, layout=torch.sparse_coo)
mt2:
 masked_tensor(
  [
    [      --,       --, 3],
    [      --,       --, 5]
  ]
)
</pre></div>
</div>
</div>
</div>
<p>Note that <code class="docutils literal notranslate"><span class="pre">mt</span></code> and <code class="docutils literal notranslate"><span class="pre">mt2</span></code> will have the same value in the vast majority of operations, but this brings us to a note on the implementation under the hood:</p>
<p><code class="docutils literal notranslate"><span class="pre">input</span></code> and <code class="docutils literal notranslate"><span class="pre">mask</span></code> - only for sparse formats - can have a different number of elements (<code class="docutils literal notranslate"><span class="pre">tensor.nnz()</span></code>) <strong>at creation</strong>, but the indices of <code class="docutils literal notranslate"><span class="pre">mask</span></code> must then be a subset of the indices from <code class="docutils literal notranslate"><span class="pre">input</span></code>. In this case, <code class="docutils literal notranslate"><span class="pre">input</span></code> will assume the shape of mask using the function <code class="docutils literal notranslate"><span class="pre">input.sparse_mask(mask)</span></code>; in other words, any of the elements in <code class="docutils literal notranslate"><span class="pre">input</span></code> that are not <code class="docutils literal notranslate"><span class="pre">True</span></code> in <code class="docutils literal notranslate"><span class="pre">mask</span></code> will be thrown away</p>
<p>Therefore, under the hood, the data looks slightly different; <code class="docutils literal notranslate"><span class="pre">mt2</span></code> has the 4 value masked out and <code class="docutils literal notranslate"><span class="pre">mt</span></code> is completely without it. In other words, their underlying data still has different shapes, so <code class="docutils literal notranslate"><span class="pre">mt</span> <span class="pre">+</span> <span class="pre">mt2</span></code> is invalid.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;mt.masked_data:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">mt</span><span class="o">.</span><span class="n">data</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;mt2.masked_data:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">mt2</span><span class="o">.</span><span class="n">data</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>mt.masked_data:
 tensor(indices=tensor([[0, 1],
                       [2, 2]]),
       values=tensor([3, 5]),
       size=(2, 3), nnz=2, layout=torch.sparse_coo)
mt2.masked_data:
 tensor(indices=tensor([[0, 1, 1],
                       [2, 0, 2]]),
       values=tensor([3, 4, 5]),
       size=(2, 3), nnz=3, layout=torch.sparse_coo)
</pre></div>
</div>
</div>
</div>
</section>
<section id="sparse-csr">
<h3>Sparse CSR<a class="headerlink" href="#sparse-csr" title="Permalink to this heading"></a></h3>
<p>We can also construct a sparse CSR MaskedTensor using sparse CSR tensors, and like the example above, they have a similar treatment under the hood.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">crow_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">col_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">mask_values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">])</span>

<span class="n">csr</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sparse_csr_tensor</span><span class="p">(</span><span class="n">crow_indices</span><span class="p">,</span> <span class="n">col_indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">double</span><span class="p">)</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sparse_csr_tensor</span><span class="p">(</span><span class="n">crow_indices</span><span class="p">,</span> <span class="n">col_indices</span><span class="p">,</span> <span class="n">mask_values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>

<span class="n">mt</span> <span class="o">=</span> <span class="n">masked_tensor</span><span class="p">(</span><span class="n">csr</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;csr tensor:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">csr</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;mask csr tensor:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">mask</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;masked tensor:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">mt</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>csr tensor:
 tensor([[1., 2.],
        [3., 4.]], dtype=torch.float64)
mask csr tensor:
 tensor([[ True, False],
        [False,  True]])
masked tensor:
 masked_tensor(
  [
    [  1.0000,       --],
    [      --,   4.0000]
  ]
)
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="overview.html" class="btn btn-neutral float-left" title="Overview of MaskedTensors" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="nan_grad.html" class="btn btn-neutral float-right" title="Distinguishing between 0 and NaN gradient" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, PyTorch.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
   

  <style>
    .wy-nav-content { max-width: 1200px !important; }
  </style>


</body>
</html>